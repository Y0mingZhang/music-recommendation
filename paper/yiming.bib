@inproceedings{anelliTopNRecommendationAlgorithms2022,
  title = {Top-{{N Recommendation Algorithms}}: {{A Quest}} for the {{State-of-the-Art}}},
  shorttitle = {Top-{{N Recommendation Algorithms}}},
  booktitle = {Proceedings of the 30th {{ACM Conference}} on {{User Modeling}}, {{Adaptation}} and {{Personalization}}},
  author = {Anelli, Vito Walter and Bellog{\'i}n, Alejandro and Di Noia, Tommaso and Jannach, Dietmar and Pomo, Claudio},
  year = {2022},
  month = jul,
  eprint = {2203.01155},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {121--131},
  doi = {10.1145/3503252.3531292},
  abstract = {Research on recommender systems algorithms, like other areas of applied machine learning, is largely dominated by efforts to improve the state-of-the-art, typically in terms of accuracy measures. Several recent research works however indicate that the reported improvements over the years sometimes "don't add up", and that methods that were published several years ago often outperform the latest models when evaluated independently. Different factors contribute to this phenomenon, including that some researchers probably often only fine-tune their own models but not the baselines. In this paper, we report the outcomes of an in-depth, systematic, and reproducible comparison of ten collaborative filtering algorithms - covering both traditional and neural models - on several common performance measures on three datasets which are frequently used for evaluation in the recent literature. Our results show that there is no consistent winner across datasets and metrics for the examined top-n recommendation task. Moreover, we find that for none of the accuracy measurements any of the considered neural models led to the best performance. Regarding the performance ranking of algorithms across the measurements, we found that linear models, nearest-neighbor methods, and traditional matrix factorization consistently perform well for the evaluated modest-sized, but commonly-used datasets. Our work shall therefore serve as a guideline for researchers regarding existing baselines to consider in future performance comparisons. Moreover, by providing a set of fine-tuned baseline models for different datasets, we hope that our work helps to establish a common understanding of the state-of-the-art for top-n recommendation tasks.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Retrieval},
  file = {/Users/yiming/Zotero/storage/5GQ3REQC/Anelli et al. - 2022 - Top-N Recommendation Algorithms A Quest for the S.pdf;/Users/yiming/Zotero/storage/C8PWQMW3/2203.html}
}

@inproceedings{bleiLatentDirichletAllocation2001,
  title = {Latent {{Dirichlet Allocation}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Blei, David and Ng, Andrew and Jordan, Michael},
  year = {2001},
  volume = {14},
  publisher = {{MIT Press}},
  abstract = {We propose a generative model for text and other collections of dis(cid:173) crete data that generalizes or improves on several previous models  including naive Bayes/unigram, mixture of unigrams  [6],  and Hof(cid:173) mann's  aspect  model,  also  known  as  probabilistic latent  semantic  indexing  (pLSI)  [3].  In  the  context  of text  modeling,  our  model  posits  that  each  document  is  generated  as  a  mixture  of  topics,  where  the  continuous-valued  mixture  proportions  are  distributed  as  a  latent  Dirichlet  random  variable.  Inference  and  learning  are  carried out efficiently  via variational  algorithms.  We  present  em(cid:173) pirical  results  on  applications  of this  model  to  problems  in  text  modeling,  collaborative filtering,  and text classification.},
  file = {/Users/yiming/Zotero/storage/F95NXPGL/Blei et al. - 2001 - Latent Dirichlet Allocation.pdf}
}

@inproceedings{herlockerAlgorithmicFrameworkPerforming1999,
  title = {An Algorithmic Framework for Performing Collaborative Filtering},
  booktitle = {Proceedings of the 22nd Annual International {{ACM SIGIR}} Conference on Research and Development in Information Retrieval},
  author = {Herlocker, Jonathan L. and Konstan, Joseph A. and Borchers, Al and Riedl, John},
  year = {1999},
  series = {{{SIGIR}} '99},
  pages = {230--237},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/312624.312682},
  isbn = {1-58113-096-1}
}

@inproceedings{resnickGroupLensOpenArchitecture1994,
  title = {{{GroupLens}}: An Open Architecture for Collaborative Filtering of Netnews},
  shorttitle = {{{GroupLens}}},
  booktitle = {Proceedings of the 1994 {{ACM}} Conference on {{Computer}} Supported Cooperative Work},
  author = {Resnick, Paul and Iacovou, Neophytos and Suchak, Mitesh and Bergstrom, Peter and Riedl, John},
  year = {1994},
  month = oct,
  series = {{{CSCW}} '94},
  pages = {175--186},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/192844.192905},
  abstract = {Collaborative filters help people make choices based on the opinions of other people. GroupLens is a system for collaborative filtering of netnews, to help people find articles they will like in the huge stream of available articles. News reader clients display predicted scores and make it easy for users to rate articles after they read them. Rating servers, called Better Bit Bureaus, gather and disseminate the ratings. The rating servers predict scores based on the heuristic that people who agreed in the past will probably agree again. Users can protect their privacy by entering ratings under pseudonyms, without reducing the effectiveness of the score prediction. The entire architecture is open: alternative software for news clients and Better Bit Bureaus can be developed independently and can interoperate with the components we have developed.},
  isbn = {978-0-89791-689-9},
  keywords = {collaborative filtering,electronic bulletin boards,information filtering,netnews,selective dissemination of information,social filtering,Usenet,user model},
  file = {/Users/yiming/Zotero/storage/T52AVBE5/Resnick et al. - 1994 - GroupLens an open architecture for collaborative .pdf}
}

@inproceedings{steckEmbarrassinglyShallowAutoencoders2019,
  title = {Embarrassingly {{Shallow Autoencoders}} for {{Sparse Data}}},
  booktitle = {The {{World Wide Web Conference}}},
  author = {Steck, Harald},
  year = {2019},
  month = may,
  series = {{{WWW}} '19},
  pages = {3251--3257},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3308558.3313710},
  abstract = {Combining simple elements from the literature, we define a linear model that is geared toward sparse data, in particular implicit feedback data for recommender systems. We show that its training objective has a closed-form solution, and discuss the resulting conceptual insights. Surprisingly, this simple model achieves better ranking accuracy than various state-of-the-art collaborative-filtering approaches, including deep non-linear models, on most of the publicly available data-sets used in our experiments.},
  isbn = {978-1-4503-6674-8},
  keywords = {Autoencoder,Closed-Form Solution,Collaborative Filtering,Linear Regression,Neighborhood Approach,Recommender System},
  file = {/Users/yiming/Zotero/storage/MJDWN3RE/Steck - 2019 - Embarrassingly Shallow Autoencoders for Sparse Dat.pdf}
}

@article{suSurveyCollaborativeFiltering2009,
  title = {A {{Survey}} of {{Collaborative Filtering Techniques}}},
  author = {Su, Xiaoyuan and Khoshgoftaar, Taghi M.},
  year = {2009},
  month = oct,
  journal = {Advances in Artificial Intelligence},
  volume = {2009},
  pages = {e421425},
  publisher = {{Hindawi}},
  issn = {1687-7470},
  doi = {10.1155/2009/421425},
  abstract = {As one of the most successful approaches to building recommender systems, collaborative filtering (CF) uses the known preferences of a group of users to make recommendations or predictions of the unknown preferences for other users. In this paper, we first introduce CF tasks and their main challenges, such as data sparsity, scalability, synonymy, gray sheep, shilling attacks, privacy protection, etc., and their possible solutions. We then present three main categories of CF techniques: memory-based, model-based, and hybrid CF algorithms (that combine CF with other recommendation techniques), with examples for representative algorithms of each category, and analysis of their predictive performance and their ability to address the challenges. From basic techniques to the state-of-the-art, we attempt to present a comprehensive survey for CF techniques, which can be served as a roadmap for research and practice in this area.},
  langid = {english},
  file = {/Users/yiming/Zotero/storage/65LHLTS6/Su and Khoshgoftaar - 2009 - A Survey of Collaborative Filtering Techniques.pdf;/Users/yiming/Zotero/storage/SC3VGCJG/421425.html}
}

@article{Schedl2018,
  title = {{Current challenges and visions in music recommender systems research}},
  author = {Schedl, M., Zamani, H., Chen, CW.},
  year = {2018},
  journal = {International Journal of Information Retrieval},
  volume = {7},
  pages = {95-116},
  issn = {1687-7470},
  doi = {10.1007/s13735-018-0154-2}
}

@article{smithTwoDecadesOfRecommenderSystemsAtAmazon.com2017,  
  author={Smith, Brent and Linden, Greg},  
  journal={IEEE Internet Computing}, 
  title={Two Decades of Recommender Systems at Amazon.com},   
  year={2017},  
  volume={21},  
  number={3}, 
  pages={12-18},  
  doi={10.1109/MIC.2017.72}
}

@article{gomezUribeTheNetflixRecommenderSystem2016,
author = {Gomez-Uribe, Carlos A. and Hunt, Neil},
title = {The Netflix Recommender System: Algorithms, Business Value, and Innovation},
year = {2016},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {2158-656X},
url = {https://doi.org/10.1145/2843948},
doi = {10.1145/2843948},
abstract = {This article discusses the various algorithms that make up the Netflix recommender system, and describes its business purpose. We also describe the role of search and related algorithms, which for us turns into a recommendations problem as well. We explain the motivations behind and review the approach that we use to improve the recommendation algorithms, combining A/B testing focused on improving member retention and medium term engagement, as well as offline experimentation using historical member engagement data. We discuss some of the issues in designing and interpreting A/B tests. Finally, we describe some current areas of focused innovation, which include making our recommender system global and language aware.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = {dec},
articleno = {13},
numpages = {19},
keywords = {Recommender systems}
}

@misc{toth2018,
  author = {James Jackson Toth},
  title = {{Too Much Music: A Failed Experiment In Dedicated Listening}},
  howpublished = "\url{https://www.npr.org/sections/therecord/2018/01/16/578216674/too-much-music-a-failed-experiment-in-dedicated-listening}",
  year = {2018}, 
  note = "[Online; accessed 2-December-2022]"
}

@misc{hilton2013,
  author = {Robin Hilton},
  title = {{Do You Really Listen To Full Albums?}},
  howpublished = "\url{https://www.npr.org/sections/allsongs/2013/05/20/185534315/do-you-really-listen-to-full-albums}",
  year = {2013}, 
  note = "[Online; accessed 2-December-2022]"
}